<!DOCTYPE html>
<html lang="english">
<head>
        <meta charset="utf-8" />
        <meta name="viewport" content="width=device-width, initial-scale=1.0" />
        <meta name="generator" content="Pelican" />
        <title>Gradient descent and stochastic gradient descent</title>
        <link rel="stylesheet" href="/theme/css/main.css" />
        <meta name="description" content="Introducing gradient descent and its applications" />
</head>

<body id="index" class="home">
        <header id="banner" class="body">
                <h1><a href="/">Heuristic Analyst</a></h1>
                <nav><ul>
                    <li><a href="/category/code.html">Code</a></li>
                    <li><a href="/category/fundamentals.html">Fundamentals</a></li>
                    <li class="active"><a href="/category/machine-learning.html">Machine Learning</a></li>
                    <li><a href="/category/quant.html">Quant</a></li>
                </ul></nav>
        </header><!-- /#banner -->
<section id="content" class="body">
  <article>
    <header>
      <h1 class="entry-title">
        <a href="/gradient-descent-and-stochastic-gradient-descent.html" rel="bookmark"
           title="Permalink to Gradient descent and stochastic gradient descent">Gradient descent and stochastic gradient descent</a></h1>
    </header>

    <div class="entry-content">
<footer class="post-info">
        <abbr class="published" title="2022-06-18T12:00:00+02:00">
                Published: Sat 18 June 2022
        </abbr>

        <address class="vcard author">
                By                         <a class="url fn" href="/author/heuristic-analyst.html">Heuristic Analyst</a>
        </address>
<p>In <a href="/category/machine-learning.html">Machine Learning</a>.</p>
<p>tags: <a href="/tag/machine-learning.html">Machine Learning</a> <a href="/tag/math-basics.html">Math basics</a> </p>
</footer><!-- /.post-info -->      <p>In this post I would like to introduce the Gradient Descent and its applications.</p>
<p>I hope that every reader of this blog is familiar with derivatives and gradients of (simple in school learned) functions, such as <span class="math">\(f(x) = 7x^{2} + 3x+ 9\)</span>. If you derive the mentioned function, you get the derivative <span class="math">\(f'(x) = 14x + 3\)</span>.</p>
<p>However, if you have functions that depend on several variables, the functions could look like this:
</p>
<div class="math">$$
\begin{align}
f(x,y) &amp;= x^{2}+y^{2} \\
\text{or }f(x_1, x_2) &amp;= x_1^{2} + x_2^{2} &amp;&amp; \text{(just a notational difference)}
\end{align}
$$</div>
<p>If you want to <strong>derive this function</strong>, you now <strong>partially derive</strong> it.</p>
<p>That means that you derive after each variable once, where in each individual derivation of a variable xᵢ all other variables are considered as constants. So you derive the function f(x₁, x₂) = x₁²+x₂² twice (with respect to x₁ and x₂).</p>
<p>This results in the following 2 derivatives:</p>
<ul>
<li>Derivative with respect to <span class="math">\(x_1\)</span>: <span class="math">\(\frac{\partial f(x_1, x_2)}{\partial x_1} = 2x_1\)</span></li>
<li>Derivative with respect to <span class="math">\(x_2\)</span>: <span class="math">\(\frac{\partial f(x_1, x_2)}{\partial x_2} = 2x_2\)</span></li>
</ul>
<p><strong><em>Sidenote</em></strong>: <span class="math">\(\partial\)</span> is the delta used to denote a partial derivative; under the fraction is the variable you derive with respect to</p>
<p>One can now combine all derivatives into a vector with the respective derivatives. This vector is called a gradient:<br>
</p>
<div class="math">$$\begin{pmatrix} 2x_1 \\ 2x_2 \end{pmatrix}$$</div>
<p>It is important to know that when calculating the gradient of a point of a function <span class="math">\(f\)</span>, the rate of change at this point is calculated (with the highest slope “in each direction”).</p>
<p>With this knowledge we can now understand the <strong>“Gradient Descent Algorithm”</strong> – An algorithm we can use to optimize a function. If we have a function to optimize, for example a <em>cost/loss function</em>, where we know the input, but we want to change the weights of the function so that the output is minimal, we can do that with this algorithm.</p>
<p><strong><em>Sidenote</em></strong>: If the function is covex, like <span class="math">\(f(x) = x^{2}\)</span>, it is called <em>convex optimization</em>, otherwise it is called <em>non-convex optimization</em>.</p>
<p>Convexity of a function to be optimized is favorable because we can also reach the global minimum of the function by using the gradient descent algorithm, whereas in the optimization of a non-convex function a local minimum may be aimed at and not the global minimum.</p>
<p>For the explanation of the gradient descent algorithm I use the sum of the squared differences, which is a function, and to be more precise a loss function, because we want to minimize the numerical value at the end.</p>
<ul>
<li><span class="math">\(f(x) = \hat{y} = \text{intercept} + \text{slope} \cdot x = b + m \cdot x\)</span></li>
<li><span class="math">\(\text{squared residuals} = (y-\hat{y})^{2} = (y-\text{intercept}-\text{slope} \cdot x)^{2}\)</span></li>
<li><span class="math">\(\text{Loss function: } L(\text{squared differences})\)</span>
    <span class="math">\(= \sum(\text{squared differences}) = (y_1-\text{intercept}-\text{slope} \cdot x_1)^{2} + \ldots + (y_i-\text{intercept}-\text{slope} \cdot x_i)^{2}\)</span></li>
</ul>
<p>For a better understanding, read the blog article on <a href="/simple-linear-regression.html">“simple linear regression“</a>!</p>
<p>Applying Gradient Descent to a function L(squared residuals) to find optimate values for interception and slope:</p>
<ul>
<li>Choose initial values of the values to be optimized, in this case for interception and slope, for example 0 and 1</li>
<li>Determine gradients (derive function <span class="math">\(\text{L(squared differences)}\)</span> according to <span class="math">\(\text{intercept}\)</span> and <span class="math">\(\text{slope}\)</span>, since we want to optimize them)  (Tipp: Because the Loss function is the sum of the squared residuals we can just <span class="math">\(\text{derive the squared differences function = (y-intercept-slope*x)}^{2}\)</span> once and sum the derivative as often as we have <span class="math">\(x\)</span>’s)</li>
<li>Calculate <span class="math">\(\text{slope}\)</span> for each derivative by using the starting values and the <span class="math">\(y\)</span>’s and <span class="math">\(x\)</span>’s</li>
<li>Calculate <span class="math">\(\text{Step Size}\)</span>: <span class="math">\(\text{Step Size = Slope} \cdot \text{Learning Rate}\)</span> (see below for what it is exactly)</li>
<li>Update the individual values to be optimized: <span class="math">\(\text{New Weight = Old Weight – Step Size}\)</span> (e.g. <span class="math">\(\text{Intercept}\)</span>: <span class="math">\(\text{New Intercept = Old Intercept – Step Size}\)</span>)</li>
<li>Repeat the steps from 3 to 5 as many times as set before (for example 10,000 times) or until the Step Size becomes smaller than e.g. 0.0001 (standard metric in machine learning) – when iterating through step 3 to 5 sthe updated values from step 5 are used at step 3 tp calculate the slope</li>
</ul>
<p><strong>What is this “Step Size”</strong>: If you think of this algorithm graphically, you first determine the slope at a point in a function. If the slope is negative, you walk in the right direction of the optimization and go one step further (<span class="math">\(\text{New Intercept = Old Intercept – (negative Step Size)}\)</span> → <span class="math">\(\text{New Intercept = Old Intercept + Step Size}\)</span>). If the slope is positive we go one step back, because we rise and walk away from the minimum. We can manipulate this step length of our walk with the so-called Learning Rate. If it is too large we may never reach the minimum because the step size is simply not granular enough. If it is too small, the computational cost can become extreme. It’s a trade-off.</p>
<p>At the end of running the algorithm, you have successfully optimized the values!</p>
<p>Now the question remains what the <strong>“Stochastic Gradient Descent”</strong> is.</p>
<p>If you calculate the gradient descent on for example a linear regression with 100 factors, you have to derive the loss function 100 times. Add to that the fact that you have 20,000,000 samples and with at least 1,000 iterations you have a total of 100<em>20,000,000</em>1,000 = 2,000,000,000,000 (2 trillion) calculations.</p>
<p>Since this takes a long time and is an extreme calculation time you can update the factors after one sample (loss function is then not the sum of all squared residuales but only the squared residual from the random sample). This is the strict definition of the stochastic gradient descent. You choose a random sample and update the factors only with the sample. This is also done about 1,000 times, but still way more efficient. In practice, however, several random samples are selected into a batch, and then optimized.</p>
<p><strong><em>Sidenote</em></strong> <strong>– ML Lingo</strong>: In modern machine learning you could have a set of factors, called features. Let’s 100 features and 60,000 samples. Now you might update the weights, slopes, intercepts, … whatever, everytime with a batchsize of 10,000. With 60,000 samples we could run 6 batches without reusing samples. This is called a epoch. So usually you need to define a batchsize and the numbers of epochs.</p>
<script type="text/javascript">if (!document.getElementById('mathjaxscript_pelican_#%@#$@#')) {
    var align = "center",
        indent = "0em",
        linebreak = "false";

    if (false) {
        align = (screen.width < 768) ? "left" : align;
        indent = (screen.width < 768) ? "0em" : indent;
        linebreak = (screen.width < 768) ? 'true' : linebreak;
    }

    var mathjaxscript = document.createElement('script');
    mathjaxscript.id = 'mathjaxscript_pelican_#%@#$@#';
    mathjaxscript.type = 'text/javascript';
    mathjaxscript.src = 'https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.3/latest.js?config=TeX-AMS-MML_HTMLorMML';

    var configscript = document.createElement('script');
    configscript.type = 'text/x-mathjax-config';
    configscript[(window.opera ? "innerHTML" : "text")] =
        "MathJax.Hub.Config({" +
        "    config: ['MMLorHTML.js']," +
        "    TeX: { extensions: ['AMSmath.js','AMSsymbols.js','noErrors.js','noUndefined.js'], equationNumbers: { autoNumber: 'none' } }," +
        "    jax: ['input/TeX','input/MathML','output/HTML-CSS']," +
        "    extensions: ['tex2jax.js','mml2jax.js','MathMenu.js','MathZoom.js']," +
        "    displayAlign: '"+ align +"'," +
        "    displayIndent: '"+ indent +"'," +
        "    showMathMenu: true," +
        "    messageStyle: 'normal'," +
        "    tex2jax: { " +
        "        inlineMath: [ ['\\\\(','\\\\)'] ], " +
        "        displayMath: [ ['$$','$$'] ]," +
        "        processEscapes: true," +
        "        preview: 'TeX'," +
        "    }, " +
        "    'HTML-CSS': { " +
        "        availableFonts: ['STIX', 'TeX']," +
        "        preferredFont: 'STIX'," +
        "        styles: { '.MathJax_Display, .MathJax .mo, .MathJax .mi, .MathJax .mn': {color: 'inherit ! important'} }," +
        "        linebreaks: { automatic: "+ linebreak +", width: '90% container' }," +
        "    }, " +
        "}); " +
        "if ('default' !== 'default') {" +
            "MathJax.Hub.Register.StartupHook('HTML-CSS Jax Ready',function () {" +
                "var VARIANT = MathJax.OutputJax['HTML-CSS'].FONTDATA.VARIANT;" +
                "VARIANT['normal'].fonts.unshift('MathJax_default');" +
                "VARIANT['bold'].fonts.unshift('MathJax_default-bold');" +
                "VARIANT['italic'].fonts.unshift('MathJax_default-italic');" +
                "VARIANT['-tex-mathit'].fonts.unshift('MathJax_default-italic');" +
            "});" +
            "MathJax.Hub.Register.StartupHook('SVG Jax Ready',function () {" +
                "var VARIANT = MathJax.OutputJax.SVG.FONTDATA.VARIANT;" +
                "VARIANT['normal'].fonts.unshift('MathJax_default');" +
                "VARIANT['bold'].fonts.unshift('MathJax_default-bold');" +
                "VARIANT['italic'].fonts.unshift('MathJax_default-italic');" +
                "VARIANT['-tex-mathit'].fonts.unshift('MathJax_default-italic');" +
            "});" +
        "}";

    (document.body || document.getElementsByTagName('head')[0]).appendChild(configscript);
    (document.body || document.getElementsByTagName('head')[0]).appendChild(mathjaxscript);
}
</script>
    </div><!-- /.entry-content -->

  </article>
</section>
        <section id="extras" class="body">
        </section><!-- /#extras -->

        <footer id="contentinfo" class="body">
                <address id="about" class="vcard body">
                Proudly powered by <a rel="nofollow" href="https://getpelican.com/">Pelican</a>, which takes great advantage of <a rel="nofollow" href="https://www.python.org/">Python</a>.
                </address><!-- /#about -->

                <p>The theme is by <a rel="nofollow" href="https://www.smashingmagazine.com/2009/08/designing-a-html-5-layout-from-scratch/">Smashing Magazine</a>, thanks!</p>
        </footer><!-- /#contentinfo -->

</body>
</html>